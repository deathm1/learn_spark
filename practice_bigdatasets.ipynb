{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    substring,\n",
    "    input_file_name,\n",
    "    current_date,\n",
    "    year,\n",
    "    like,\n",
    "    asc,\n",
    "    desc,\n",
    "    count,\n",
    "    count_distinct,\n",
    "    max,\n",
    "    min,\n",
    "    avg,\n",
    "    array_agg,\n",
    "    array_distinct,\n",
    "    array_contains,\n",
    "    row_number,\n",
    "    rank,\n",
    "    dense_rank,\n",
    "    ntile,\n",
    "    sum,\n",
    "    lead,\n",
    "    lag,\n",
    "    cume_dist,\n",
    ")\n",
    "\n",
    "\n",
    "from pyspark.sql.types import (\n",
    "    IntegerType,\n",
    "    LongType,\n",
    "    StructField,\n",
    "    StructType,\n",
    "    DateType,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    "    TimestampType,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SparkSession.builder.config(\n",
    "    \"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\"\n",
    ").config(\n",
    "    \"spark.sql.catalog.spark_catalog\",\n",
    "    \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    ")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data into spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_user_schema = StructType(\n",
    "    [\n",
    "        StructField(\"index\", IntegerType(), nullable=False),\n",
    "        StructField(\"organization_id\", StringType(), nullable=False),\n",
    "        StructField(\"name\", StringType(), nullable=False),\n",
    "        StructField(\"website\", StringType(), nullable=False),\n",
    "        StructField(\"country\", StringType(), nullable=False),\n",
    "        StructField(\"description\", StringType(), nullable=False),\n",
    "        StructField(\"founded\", IntegerType(), nullable=False),\n",
    "        StructField(\"industry\", StringType(), nullable=False),\n",
    "        StructField(\"employee_no\", IntegerType(), nullable=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "users_df = (\n",
    "    spark.read.option(\"header\", True)\n",
    "    .schema(my_user_schema)\n",
    "    .csv(\"./datasets/organizations-2000000.csv\")\n",
    ")\n",
    "\n",
    "\n",
    "click_data_schema = StructType(\n",
    "    [\n",
    "        StructField(\"session_id\", IntegerType(), nullable=False),\n",
    "        StructField(\"IPID\", IntegerType(), nullable=False),\n",
    "        StructField(\"timestamp\", TimestampType(), nullable=False),\n",
    "        StructField(\"VHOST\", StringType(), nullable=False),\n",
    "        StructField(\"URL_FILE\", StringType(), nullable=False),\n",
    "        StructField(\"PAGE_NAME\", StringType(), nullable=False),\n",
    "        StructField(\"REF_URL_category\", StringType(), nullable=False),\n",
    "        StructField(\"page_load_error\", IntegerType(), nullable=False),\n",
    "        StructField(\"page_action_detail\", StringType(), nullable=False),\n",
    "        StructField(\"tip\", StringType(), nullable=False),\n",
    "        StructField(\"service_detail\", StringType(), nullable=False),\n",
    "        StructField(\"xps_info\", StringType(), nullable=False),\n",
    "        StructField(\"page_action_detail_EN\", StringType(), nullable=False),\n",
    "        StructField(\"service_detail_EN\", StringType(), nullable=False),\n",
    "        StructField(\"tip_EN\", StringType(), nullable=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "click_data_df = (\n",
    "    spark.read.option(\"header\", True)\n",
    "    .option(\"delimiter\", \";\")\n",
    "    .schema(click_data_schema)\n",
    "    .csv(\"./datasets/BPI2016_Clicks_NOT_Logged_In.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting dataframes to delta tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users_df.write.mode(\"overwrite\").format(\"delta\").save(\"./output/users_df_delta\")\n",
    "# click_data_df.write.mode(\"overwrite\").format(\"delta\").save(\n",
    "#     \"./output/click_data_df_delta\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying delta tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|version|           timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|      1|2024-01-17 14:01:...|  NULL|    NULL| OPTIMIZE|{predicate -> [],...|NULL|    NULL|     NULL|          0|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Apache-Spark/3.5....|\n",
      "|      0|2024-01-17 13:54:...|  NULL|    NULL|    WRITE|{mode -> Overwrit...|NULL|    NULL|     NULL|       NULL|     Serializable|        false|{numFiles -> 8, n...|        NULL|Apache-Spark/3.5....|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|version|           timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|      1|2024-01-17 14:03:...|  NULL|    NULL| OPTIMIZE|{predicate -> [],...|NULL|    NULL|     NULL|          0|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Apache-Spark/3.5....|\n",
      "|      0|2024-01-17 13:54:...|  NULL|    NULL|    WRITE|{mode -> Overwrit...|NULL|    NULL|     NULL|       NULL|     Serializable|        false|{numFiles -> 9, n...|        NULL|Apache-Spark/3.5....|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "DESCRIBE HISTORY delta.`D:\\\\development\\\\learn_spark\\\\output\\\\users_df_delta`;\n",
    "\"\"\"\n",
    ").show()\n",
    "\n",
    "\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "DESCRIBE HISTORY delta.`D:\\\\development\\\\learn_spark\\\\output\\\\click_data_df_delta`;\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing EDA on data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- session_id: integer (nullable = true)\n",
      " |-- IPID: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- VHOST: string (nullable = true)\n",
      " |-- URL_FILE: string (nullable = true)\n",
      " |-- PAGE_NAME: string (nullable = true)\n",
      " |-- REF_URL_category: string (nullable = true)\n",
      " |-- page_load_error: integer (nullable = true)\n",
      " |-- page_action_detail: string (nullable = true)\n",
      " |-- tip: string (nullable = true)\n",
      " |-- service_detail: string (nullable = true)\n",
      " |-- xps_info: string (nullable = true)\n",
      " |-- page_action_detail_EN: string (nullable = true)\n",
      " |-- service_detail_EN: string (nullable = true)\n",
      " |-- tip_EN: string (nullable = true)\n",
      "\n",
      "+----------+-------+--------------------+-------------+--------------------+------------------+----------------+---------------+------------------+----+--------------+--------------------+---------------------+-----------------+------+\n",
      "|session_id|   IPID|           timestamp|        VHOST|            URL_FILE|         PAGE_NAME|REF_URL_category|page_load_error|page_action_detail| tip|service_detail|            xps_info|page_action_detail_EN|service_detail_EN|tip_EN|\n",
      "+----------+-------+--------------------+-------------+--------------------+------------------+----------------+---------------+------------------+----+--------------+--------------------+---------------------+-----------------+------+\n",
      "|  43581744| 849196|2015-12-23 10:23:...|  www.werk.nl|  /xpsitem/ptl260281|         ptl260281|            NULL|              0|              NULL|NULL|          NULL|download_model_ar...|                 NULL|             NULL|  NULL|\n",
      "|  41683444|2110820|2015-12-15 12:30:...|  www.werk.nl|/werk_nl/werkneme...|              home|      Logged Out|              0|              NULL|NULL|          NULL|                NULL|                 NULL|             NULL|  NULL|\n",
      "|  39411578|1651304|2015-12-15 10:53:...|  www.werk.nl|/werk_nl/werkneme...|         vacatures|            NULL|              0|              NULL|NULL|          NULL|                NULL|                 NULL|             NULL|  NULL|\n",
      "|  39122892|   5121|2015-12-16 14:33:...|  www.werk.nl|//werk_nl/werknem...|       inschrijven|             UWV|              0|              NULL|NULL|          NULL|                NULL|                 NULL|             NULL|  NULL|\n",
      "|  41017721| 428116|2016-01-04 11:59:...|digid.werk.nl|/portal/page/port...|aanvragen-bijstand|            NULL|              0|              NULL|NULL|1. Uw situatie|                NULL|                 NULL|1. Your situation|  NULL|\n",
      "+----------+-------+--------------------+-------------+--------------------+------------------+----------------+---------------+------------------+----+--------------+--------------------+---------------------+-----------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- organization_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- website: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- founded: integer (nullable = true)\n",
      " |-- industry: string (nullable = true)\n",
      " |-- employee_no: integer (nullable = true)\n",
      "\n",
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+-------------------+-----------+\n",
      "|index|organization_id|                name|             website|             country|         description|founded|           industry|employee_no|\n",
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+-------------------+-----------+\n",
      "|    1|391dAA77fea9EC1|      Daniel-Mcmahon|https://stuart-ri...|            Cambodia|Focused eco-centr...|   2013|             Sports|       1878|\n",
      "|    2|9FcCA4A23e6BcfA|Mcdowell, Tate an...|  http://jacobs.biz/|              Guyana|Front-line real-t...|   2018|     Legal Services|       9743|\n",
      "|    3|DB23330238B7B3D|Roberts, Carson a...|http://www.park.com/|              Jordan|Innovative hybrid...|   1992|        Hospitality|       7537|\n",
      "|    4|bbf18835CFbEee7|Poole, Jefferson ...|  http://hayden.com/|Cocos (Keeling) I...|Extended regional...|   1991|    Food Production|       9974|\n",
      "|    5|74ECD725ceaDfd9|Ritter, Patel and...|https://www.mason...|             Ecuador|Re-contextualized...|   2019|Computer Networking|       5050|\n",
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+-------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(\"./output/click_data_df_delta/\").printSchema()\n",
    "spark.read.format(\"delta\").load(\"./output/click_data_df_delta/\").show(5)\n",
    "\n",
    "spark.read.format(\"delta\").load(\"./output/users_df_delta/\").printSchema()\n",
    "spark.read.format(\"delta\").load(\"./output/users_df_delta/\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizations\n",
    "\n",
    "1. In first dataset it is a good choice to z-order the dataset by page name so the records corresponding to the same page are co-located\n",
    "2. In the second dataset the same logic as point 1 is there for the country attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\n",
    "#     \"\"\"\n",
    "# OPTIMIZE delta.`D:\\\\development\\\\learn_spark\\\\output\\\\users_df_delta` ZORDER BY (country);\n",
    "# \"\"\"\n",
    "# ).show()\n",
    "# spark.sql(\n",
    "#     \"\"\"\n",
    "# OPTIMIZE delta.`D:\\\\development\\\\learn_spark\\\\output\\\\click_data_df_delta` ZORDER BY (PAGE_NAME);\n",
    "# \"\"\"\n",
    "# ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+---------+------------------------------------------+----+--------+---------+-----------+-----------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                       |job |notebook|clusterId|readVersion|isolationLevel   |isBlindAppend|operationMetrics                                                                                                                                                                                                                                                      |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+------------------------------------------+----+--------+---------+-----------+-----------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|1      |2024-01-17 14:01:47.535|NULL  |NULL    |OPTIMIZE |{predicate -> [], zOrderBy -> [\"country\"]}|NULL|NULL    |NULL     |0          |SnapshotIsolation|false        |{numRemovedFiles -> 8, numRemovedBytes -> 120336344, p25FileSize -> 120941341, numDeletionVectorsRemoved -> 0, minFileSize -> 120941341, numAddedFiles -> 1, maxFileSize -> 120941341, p75FileSize -> 120941341, p50FileSize -> 120941341, numAddedBytes -> 120941341}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|0      |2024-01-17 13:54:01.032|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}    |NULL|NULL    |NULL     |NULL       |Serializable     |false        |{numFiles -> 8, numOutputRows -> 2000000, numOutputBytes -> 120336344}                                                                                                                                                                                                |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "+-------+-----------------------+------+--------+---------+------------------------------------------+----+--------+---------+-----------+-----------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------------+----+--------+---------+-----------+-----------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                         |job |notebook|clusterId|readVersion|isolationLevel   |isBlindAppend|operationMetrics                                                                                                                                                                                                                                                      |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------------+----+--------+---------+-----------+-----------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|1      |2024-01-17 14:03:49.142|NULL  |NULL    |OPTIMIZE |{predicate -> [], zOrderBy -> [\"PAGE_NAME\"]}|NULL|NULL    |NULL     |0          |SnapshotIsolation|false        |{numRemovedFiles -> 9, numRemovedBytes -> 154394588, p25FileSize -> 157316493, numDeletionVectorsRemoved -> 0, minFileSize -> 157316493, numAddedFiles -> 1, maxFileSize -> 157316493, p75FileSize -> 157316493, p50FileSize -> 157316493, numAddedBytes -> 157316493}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|0      |2024-01-17 13:54:37.775|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}      |NULL|NULL    |NULL     |NULL       |Serializable     |false        |{numFiles -> 9, numOutputRows -> 9329418, numOutputBytes -> 154394588}                                                                                                                                                                                                |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------------+----+--------+---------+-----------+-----------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "DESCRIBE HISTORY delta.`D:\\\\development\\\\learn_spark\\\\output\\\\users_df_delta`;\n",
    "\"\"\"\n",
    ").show(truncate=False)\n",
    "\n",
    "\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "DESCRIBE HISTORY delta.`D:\\\\development\\\\learn_spark\\\\output\\\\click_data_df_delta`;\n",
    "\"\"\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading delta tables in spark dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_delta_table_v1 = (\n",
    "    spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"./output/users_df_delta/\")\n",
    ")\n",
    "user_delta_table_v2 = (\n",
    "    spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(\"./output/users_df_delta/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_delta_table_v2.createOrReplaceTempView(\"user_delta_table_v2_tv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------\n",
      " index           | 1                             \n",
      " organization_id | 391dAA77fea9EC1               \n",
      " name            | Daniel-Mcmahon                \n",
      " website         | https://stuart-rios.biz/      \n",
      " country         | Cambodia                      \n",
      " description     | Focused eco-centric help-desk \n",
      " founded         | 2013                          \n",
      " industry        | Sports                        \n",
      " employee_no     | 1878                          \n",
      "-RECORD 1----------------------------------------\n",
      " index           | 2                             \n",
      " organization_id | 9FcCA4A23e6BcfA               \n",
      " name            | Mcdowell, Tate and Murray     \n",
      " website         | http://jacobs.biz/            \n",
      " country         | Guyana                        \n",
      " description     | Front-line real-time portal   \n",
      " founded         | 2018                          \n",
      " industry        | Legal Services                \n",
      " employee_no     | 9743                          \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_delta_table_v2.show(2, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfrom Group By and aggregations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+--------------------+--------------+\n",
      "|employee_no|employee_count|        country_list|contains_india|\n",
      "+-----------+--------------+--------------------+--------------+\n",
      "|       4846|           261|[Samoa, Malta, Ja...|          true|\n",
      "|       2384|           251|[Slovakia (Slovak...|          true|\n",
      "|       3390|           250|[Rwanda, Uruguay,...|         false|\n",
      "|       1589|           249|[Iran, Puerto Ric...|          true|\n",
      "|       1961|           247|[Macedonia, Malay...|         false|\n",
      "+-----------+--------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\n",
    "#     \"\"\"\n",
    "#     SELECT\n",
    "#     name,\n",
    "#     count(distinct country) as distinct_country_count,\n",
    "#     count(distinct employee_no) as distinct_no_of_employees\n",
    "#     from user_delta_table_v2_tv\n",
    "#     group by name\n",
    "#     order by distinct_no_of_employees desc;\n",
    "#     \"\"\"\n",
    "# ).show(5)\n",
    "\n",
    "\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "    \n",
    "    employee_no,\n",
    "    count(employee_no) as employee_count,\n",
    "    array_distinct(array_agg(country)) as country_list,\n",
    "    array_contains(array_agg(country), 'India') as contains_india\n",
    "\n",
    "    from user_delta_table_v2_tv \n",
    "    group by employee_no\n",
    "    order by employee_count desc;\n",
    "    \"\"\"\n",
    ").show(5)\n",
    "\n",
    "\n",
    "# spark.sql(\n",
    "#     \"\"\"\n",
    "#     SELECT * from user_delta_table_v2_tv where name like '%Bradley PLC%';\n",
    "#     \"\"\"\n",
    "# ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+---------------------+---------------+-----------------+\n",
      "|employee_no|employee_no_count|distinct_country_list|is_india_a_part|average_employees|\n",
      "+-----------+-----------------+---------------------+---------------+-----------------+\n",
      "|       4846|              261| [Samoa, Malta, Ja...|           true|           4846.0|\n",
      "|       2384|              251| [Slovakia (Slovak...|           true|           2384.0|\n",
      "|       3390|              250| [Rwanda, Uruguay,...|          false|           3390.0|\n",
      "|       1589|              249| [Iran, Puerto Ric...|           true|           1589.0|\n",
      "|       7828|              247| [Saint Vincent an...|           true|           7828.0|\n",
      "+-----------+-----------------+---------------------+---------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_delta_table_v2.groupBy(\"employee_no\").agg(\n",
    "    count(user_delta_table_v2.employee_no).alias(\"employee_no_count\"),\n",
    "    array_distinct(array_agg(user_delta_table_v2.country)).alias(\n",
    "        \"distinct_country_list\"\n",
    "    ),\n",
    "    array_contains(array_agg(user_delta_table_v2.country), \"India\").alias(\n",
    "        \"is_india_a_part\"\n",
    "    ),\n",
    "    avg(user_delta_table_v2.employee_no).alias(\"average_employees\"),\n",
    ").sort(desc(\"employee_no_count\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windowing on data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_salaries_df = spark.read.options(header=True, inferSchema=True).csv(\n",
    "    \"./datasets/ds_salaries.csv\"\n",
    ")\n",
    "ds_salaries_df.createOrReplaceTempView(\"ds_salaries_tv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available functions\n",
    "\n",
    "- Simple aggregation functions: avg, sum, min, max, count\n",
    "- Row-wise ordering and ranking functions: row_number, rank, dense_rank, percent_rank, ntile (divides data into n buckets)\n",
    "- Creating lagged columns: lag, lead\n",
    "- Combining Windows and Calling Functions: over\n",
    "- Analytic functions: cume_dist, first_value, last_value, nth_value\n",
    "- Aggregate functions: collect_list, collect_set, corr, covar_pop, covar_samp, stddev, stddev_pop, stddev_samp, variance, var_pop, var_samp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+------+----+----------+------------------+-----+------+-----+------------------+------+------+------+-------------------+\n",
      "|_c0|work_year|experience_level|employment_type|           job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|row_no|rank|dense_rank|      percent_rank|ntile|  lead|  lag|               avg|   min|   max|   sum|            cumdist|\n",
      "+---+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+------+----+----------+------------------+-----+------+-----+------------------+------+------+------+-------------------+\n",
      "| 77|     2021|              MI|             PT|3D Computer Visio...|400000|            INR|         5409|                IN|          50|              IN|           M|     1|   1|         1|               0.0|    1|   404|  404|          400000.0|400000|400000|400000|                1.0|\n",
      "| 96|     2021|              EN|             PT|        AI Scientist| 12000|            USD|        12000|                BR|         100|              US|           S|     1|   1|         1|               0.0|    1| 12000|  404|           12000.0| 12000| 12000| 24000| 0.2857142857142857|\n",
      "|113|     2021|              EN|             PT|        AI Scientist| 12000|            USD|        12000|                PK|         100|              US|           M|     2|   1|         1|               0.0|    1| 55000|12000|           12000.0| 12000| 12000| 24000| 0.2857142857142857|\n",
      "|277|     2021|              SE|             FT|        AI Scientist| 55000|            USD|        55000|                ES|         100|              ES|           L|     3|   3|         2|0.3333333333333333|    1|120000|12000|26333.333333333332| 12000| 55000| 79000|0.42857142857142855|\n",
      "|391|     2022|              MI|             FT|        AI Scientist|120000|            USD|       120000|                US|           0|              US|           M|     4|   4|         3|               0.5|    2|200000|55000|           49750.0| 12000|120000|199000| 0.5714285714285714|\n",
      "+---+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+------+----+----------+------------------+-----+------+-----+------------------+------+------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "select \n",
    "tab.*,\n",
    "ROW_NUMBER() OVER(PARTITION BY job_title ORDER BY salary) as row_no,\n",
    "RANK() OVER(PARTITION BY job_title ORDER BY salary) as rank,\n",
    "dense_rank() OVER(PARTITION BY job_title ORDER BY salary) as dense_rank,\n",
    "PERCENT_RANK() OVER(PARTITION BY job_title ORDER BY salary) as percent_rank,\n",
    "NTILE(3) OVER(PARTITION BY job_title ORDER BY salary) as ntile,\n",
    "lead(salary, 1, 404) OVER(PARTITION BY job_title ORDER BY salary) as lead,\n",
    "lag(salary, 1, 404) OVER(PARTITION BY job_title ORDER BY salary) as lag,\n",
    "\n",
    "avg(salary) OVER(PARTITION BY job_title ORDER BY salary) as avg,\n",
    "min(salary) OVER(PARTITION BY job_title ORDER BY salary) as min,\n",
    "max(salary) OVER(PARTITION BY job_title ORDER BY salary) as max,\n",
    "sum(salary) OVER(PARTITION BY job_title ORDER BY salary) as sum,\n",
    "cume_dist() OVER(PARTITION BY job_title ORDER BY salary) as cumdist\n",
    "from ds_salaries_tv as tab;\n",
    "\"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+----------+----+----------+------------------+------+--------+--------+--------+------+-------------------+\n",
      "|_c0|work_year|experience_level|employment_type|           job_title|  salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|row_number|rank|dense_rank|               avg|   min|     max|     sum|    lead|   lag|          cume_dist|\n",
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+----------+----+----------+------------------+------+--------+--------+--------+------+-------------------+\n",
      "| 77|     2021|              MI|             PT|3D Computer Visio...|  400000|            INR|         5409|                IN|          50|              IN|           M|         1|   1|         1|          400000.0|400000|  400000|  400000|    NULL|  NULL|                1.0|\n",
      "| 96|     2021|              EN|             PT|        AI Scientist|   12000|            USD|        12000|                BR|         100|              US|           S|         1|   1|         1|           12000.0| 12000|   12000|   24000|   55000|  NULL| 0.2857142857142857|\n",
      "|113|     2021|              EN|             PT|        AI Scientist|   12000|            USD|        12000|                PK|         100|              US|           M|         2|   1|         1|           12000.0| 12000|   12000|   24000|  120000|  NULL| 0.2857142857142857|\n",
      "|277|     2021|              SE|             FT|        AI Scientist|   55000|            USD|        55000|                ES|         100|              ES|           L|         3|   3|         2|26333.333333333332| 12000|   55000|   79000|  200000| 12000|0.42857142857142855|\n",
      "|391|     2022|              MI|             FT|        AI Scientist|  120000|            USD|       120000|                US|           0|              US|           M|         4|   4|         3|           49750.0| 12000|  120000|  199000|  300000| 12000| 0.5714285714285714|\n",
      "|606|     2022|              MI|             FT|        AI Scientist|  200000|            USD|       200000|                IN|         100|              US|           L|         5|   5|         4|           79800.0| 12000|  200000|  399000| 1335000| 55000| 0.7142857142857143|\n",
      "| 52|     2020|              EN|             FT|        AI Scientist|  300000|            DKK|        45896|                DK|          50|              DK|           S|         6|   6|         5|          116500.0| 12000|  300000|  699000|    NULL|120000| 0.8571428571428571|\n",
      "|244|     2021|              EN|             FT|        AI Scientist| 1335000|            INR|        18053|                IN|         100|              AS|           S|         7|   7|         6| 290571.4285714286| 12000| 1335000| 2034000|    NULL|200000|                1.0|\n",
      "|368|     2022|              EX|             FT|  Analytics Engineer|  135000|            USD|       135000|                US|         100|              US|           M|         1|   1|         1|          135000.0|135000|  135000|  135000|  184700|  NULL|               0.25|\n",
      "|344|     2022|              EX|             FT|  Analytics Engineer|  175000|            USD|       175000|                US|         100|              US|           M|         2|   2|         2|          155000.0|135000|  175000|  310000|  205300|  NULL|                0.5|\n",
      "|561|     2022|              SE|             FT|  Analytics Engineer|  184700|            USD|       184700|                US|           0|              US|           M|         3|   3|         3|          164900.0|135000|  184700|  494700|    NULL|135000|               0.75|\n",
      "|560|     2022|              SE|             FT|  Analytics Engineer|  205300|            USD|       205300|                US|           0|              US|           M|         4|   4|         4|          175000.0|135000|  205300|  700000|    NULL|175000|                1.0|\n",
      "| 82|     2021|              MI|             FT|Applied Data Scie...|   68000|            CAD|        54238|                GB|          50|              CA|           L|         1|   1|         1|           68000.0| 68000|   68000|   68000|  157000|  NULL|                0.2|\n",
      "|123|     2021|              EN|             FT|Applied Data Scie...|   80000|            GBP|       110037|                GB|           0|              GB|           L|         2|   2|         2|           74000.0| 68000|   80000|  148000|  177000|  NULL|                0.4|\n",
      "|509|     2022|              MI|             FT|Applied Data Scie...|  157000|            USD|       157000|                US|         100|              US|           L|         3|   3|         3|101666.66666666667| 68000|  157000|  305000|  380000| 68000|                0.6|\n",
      "|525|     2022|              SE|             FT|Applied Data Scie...|  177000|            USD|       177000|                US|         100|              US|           L|         4|   4|         4|          120500.0| 68000|  177000|  482000|    NULL| 80000|                0.8|\n",
      "|519|     2022|              SE|             FT|Applied Data Scie...|  380000|            USD|       380000|                US|         100|              US|           L|         5|   5|         5|          172400.0| 68000|  380000|  862000|    NULL|157000|                1.0|\n",
      "|489|     2022|              EN|             CT|Applied Machine L...|   29000|            EUR|        31875|                TN|         100|              CZ|           M|         1|   1|         1|           29000.0| 29000|   29000|   29000|   75000|  NULL|               0.25|\n",
      "|132|     2021|              MI|             FT|Applied Machine L...|   38400|            USD|        38400|                VN|         100|              US|           M|         2|   2|         2|           33700.0| 29000|   38400|   67400|  423000|  NULL|                0.5|\n",
      "|506|     2022|              MI|             FT|Applied Machine L...|   75000|            USD|        75000|                BO|         100|              US|           L|         3|   3|         3|47466.666666666664| 29000|   75000|  142400|    NULL| 29000|               0.75|\n",
      "|157|     2021|              MI|             FT|Applied Machine L...|  423000|            USD|       423000|                US|          50|              US|           L|         4|   4|         4|          141350.0| 29000|  423000|  565400|    NULL| 38400|                1.0|\n",
      "|196|     2021|              EN|             FT|     BI Data Analyst|    9272|            USD|         9272|                KE|         100|              KE|           S|         1|   1|         1|            9272.0|  9272|    9272|    9272|   98000|  NULL|0.16666666666666666|\n",
      "|168|     2021|              EN|             FT|     BI Data Analyst|   55000|            USD|        55000|                US|          50|              US|           S|         2|   2|         2|           32136.0|  9272|   55000|   64272|  100000|  NULL| 0.3333333333333333|\n",
      "| 23|     2020|              MI|             FT|     BI Data Analyst|   98000|            USD|        98000|                US|           0|              US|           M|         3|   3|         3|54090.666666666664|  9272|   98000|  162272|  150000|  9272|                0.5|\n",
      "| 76|     2021|              MI|             FT|     BI Data Analyst|  100000|            USD|       100000|                US|         100|              US|           M|         4|   4|         4|           65568.0|  9272|  100000|  262272|11000000| 55000| 0.6666666666666666|\n",
      "| 73|     2021|              EX|             FT|     BI Data Analyst|  150000|            USD|       150000|                IN|         100|              US|           L|         5|   5|         5|           82454.4|  9272|  150000|  412272|    NULL| 98000| 0.8333333333333334|\n",
      "|102|     2021|              MI|             FT|     BI Data Analyst|11000000|            HUF|        36259|                HU|          50|              US|           L|         6|   6|         6|1902045.3333333333|  9272|11000000|11412272|    NULL|100000|                1.0|\n",
      "|255|     2021|              SE|             FT|  Big Data Architect|  125000|            CAD|        99703|                CA|          50|              CA|           M|         1|   1|         1|          125000.0|125000|  125000|  125000|    NULL|  NULL|                1.0|\n",
      "|192|     2021|              MI|             FT|   Big Data Engineer|   18000|            USD|        18000|                MD|           0|              MD|           S|         1|   1|         1|           18000.0| 18000|   18000|   18000|   70000|  NULL|              0.125|\n",
      "|120|     2021|              MI|             FT|   Big Data Engineer|   60000|            USD|        60000|                ES|          50|              RO|           M|         2|   2|         2|           39000.0| 18000|   60000|   78000|   85000|  NULL|               0.25|\n",
      "| 31|     2020|              EN|             FT|   Big Data Engineer|   70000|            USD|        70000|                US|         100|              US|           L|         3|   3|         3|49333.333333333336| 18000|   70000|  148000|  100000| 18000|              0.375|\n",
      "|  2|     2020|              SE|             FT|   Big Data Engineer|   85000|            GBP|       109024|                GB|          50|              GB|           M|         4|   4|         4|           58250.0| 18000|   85000|  233000|  435000| 60000|                0.5|\n",
      "| 17|     2020|              SE|             FT|   Big Data Engineer|  100000|            EUR|       114047|                PL|         100|              GB|           S|         5|   5|         5|           66600.0| 18000|  100000|  333000| 1200000| 70000|              0.625|\n",
      "|213|     2021|              EN|             FT|   Big Data Engineer|  435000|            INR|         5882|                IN|           0|              CH|           L|         6|   6|         6|          128000.0| 18000|  435000|  768000| 1672000| 85000|               0.75|\n",
      "|230|     2021|              EN|             FT|   Big Data Engineer| 1200000|            INR|        16228|                IN|         100|              IN|           L|         7|   7|         7|281142.85714285716| 18000| 1200000| 1968000|    NULL|100000|              0.875|\n",
      "|180|     2021|              MI|             FT|   Big Data Engineer| 1672000|            INR|        22611|                IN|           0|              IN|           L|         8|   8|         8|          455000.0| 18000| 1672000| 3640000|    NULL|435000|                1.0|\n",
      "|279|     2021|              EN|             FT|Business Data Ana...|   50000|            EUR|        59102|                LU|         100|              LU|           L|         1|   1|         1|           50000.0| 50000|   50000|   50000|  100000|  NULL|                0.2|\n",
      "|511|     2022|              MI|             FT|Business Data Ana...|   90000|            CAD|        70912|                CA|          50|              CA|           L|         2|   2|         2|           70000.0| 50000|   90000|  140000|  135000|  NULL|                0.4|\n",
      "| 28|     2020|              EN|             CT|Business Data Ana...|  100000|            USD|       100000|                US|         100|              US|           L|         3|   3|         3|           80000.0| 50000|  100000|  240000| 1400000| 50000|                0.6|\n",
      "|  8|     2020|              MI|             FT|Business Data Ana...|  135000|            USD|       135000|                US|         100|              US|           L|         4|   4|         4|           93750.0| 50000|  135000|  375000|    NULL| 90000|                0.8|\n",
      "|458|     2022|              MI|             FT|Business Data Ana...| 1400000|            INR|        18442|                IN|         100|              IN|           M|         5|   5|         5|          355000.0| 50000| 1400000| 1775000|    NULL|100000|                1.0|\n",
      "| 95|     2021|              MI|             FT| Cloud Data Engineer|  120000|            SGD|        89294|                SG|          50|              SG|           L|         1|   1|         1|          120000.0|120000|  120000|  120000|    NULL|  NULL|                0.5|\n",
      "|149|     2021|              SE|             FT| Cloud Data Engineer|  160000|            USD|       160000|                BR|         100|              US|           S|         2|   2|         2|          140000.0|120000|  160000|  280000|    NULL|  NULL|                1.0|\n",
      "|521|     2022|              EN|             FT|Computer Vision E...|   10000|            USD|        10000|                PT|         100|              LU|           M|         1|   1|         1|           10000.0| 10000|   10000|   10000|   60000|  NULL|0.16666666666666666|\n",
      "|133|     2021|              SE|             FT|Computer Vision E...|   24000|            USD|        24000|                BR|         100|              BR|           M|         2|   2|         2|           17000.0| 10000|   24000|   34000|  102000|  NULL| 0.3333333333333333|\n",
      "| 54|     2020|              SE|             FL|Computer Vision E...|   60000|            USD|        60000|                RU|         100|              US|           S|         3|   3|         3|31333.333333333332| 10000|   60000|   94000|  125000| 10000|                0.5|\n",
      "|271|     2021|              SE|             FT|Computer Vision E...|  102000|            BRL|        18907|                BR|           0|              BR|           M|         4|   4|         4|           49000.0| 10000|  102000|  196000|  180000| 24000| 0.6666666666666666|\n",
      "|454|     2022|              EN|             FT|Computer Vision E...|  125000|            USD|       125000|                US|           0|              US|           M|         5|   5|         5|           64200.0| 10000|  125000|  321000|    NULL| 60000| 0.8333333333333334|\n",
      "|216|     2021|              EN|             PT|Computer Vision E...|  180000|            DKK|        28609|                DK|          50|              DK|           S|         6|   6|         6|           83500.0| 10000|  180000|  501000|    NULL|102000|                1.0|\n",
      "| 98|     2021|              EN|             FT|Computer Vision S...|   70000|            USD|        70000|                US|         100|              US|           M|         1|   1|         1|           70000.0| 70000|   70000|   70000|  150000|  NULL| 0.3333333333333333|\n",
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+----------+----+----------+------------------+------+--------+--------+--------+------+-------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.partitionBy(\"job_title\").orderBy(\"salary\")\n",
    "\n",
    "\n",
    "ds_salaries_df.withColumn(\"row_number\", row_number().over(windowSpec)).withColumn(\n",
    "    \"rank\", rank().over(windowSpec)\n",
    ").withColumn(\"dense_rank\", dense_rank().over(windowSpec)).withColumn(\n",
    "    \"avg\", avg(col(\"salary\")).over(windowSpec)\n",
    ").withColumn(\n",
    "    \"min\", min(col(\"salary\")).over(windowSpec)\n",
    ").withColumn(\n",
    "    \"max\", max(col(\"salary\")).over(windowSpec)\n",
    ").withColumn(\n",
    "    \"sum\", sum(col(\"salary\")).over(windowSpec)\n",
    ").withColumn(\n",
    "    \"lead\", lead(\"salary\", 2).over(windowSpec)\n",
    ").withColumn(\n",
    "    \"lag\", lag(\"salary\", 2).over(windowSpec)\n",
    ").withColumn(\n",
    "    \"cume_dist\", cume_dist().over(windowSpec)\n",
    ").show(\n",
    "    50\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
