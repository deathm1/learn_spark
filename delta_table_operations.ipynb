{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, window\n",
    "from delta import configure_spark_with_delta_pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SparkSession.builder.config(\n",
    "    \"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\"\n",
    ").config(\n",
    "    \"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
    ")\n",
    "\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = spark.sql(\n",
    "    \"\"\"\n",
    "select 5 as col1, 6 as col2 union select 7 as col1, 8 as col2;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydf.write.format('delta').mode('overwrite').save(\"./output/testdeltatable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                                                           |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|2      |2024-01-19 22:09:22.127|NULL  |NULL    |RESTORE  |{version -> 0, timestamp -> NULL}     |NULL|NULL    |NULL     |1          |Serializable  |false        |{numRestoredFiles -> 1, removedFilesSize -> 692, numRemovedFiles -> 1, restoredFilesSize -> 692, numOfFilesAfterRestore -> 1, tableSizeAfterRestore -> 692}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|1      |2024-01-19 22:04:25.781|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |0          |Serializable  |false        |{numFiles -> 1, numOutputRows -> 2, numOutputBytes -> 692}                                                                                                 |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|0      |2024-01-19 22:04:11.99 |NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 2, numOutputBytes -> 692}                                                                                                 |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtname = \"delta.`F:\\\\development\\\\learn_spark\\\\output\\\\testdeltatable`\"\n",
    "\n",
    "spark.sql(f\"describe history {dtname};\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Specific Version from delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   1|   2|\n",
      "|   3|   4|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\n",
    "    \"./output/testdeltatable/\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|5   |6   |\n",
      "|7   |8   |\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"select * from {dtname} VERSION AS OF 1;\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roll back delta table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------------------+-----------------+------------------+------------------+-------------------+\n",
      "|table_size_after_restore|num_of_files_after_restore|num_removed_files|num_restored_files|removed_files_size|restored_files_size|\n",
      "+------------------------+--------------------------+-----------------+------------------+------------------+-------------------+\n",
      "|692                     |1                         |0                |0                 |0                 |0                  |\n",
      "+------------------------+--------------------------+-----------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"RESTORE TABLE {dtname} VERSION AS OF 0;\").show(truncate=False)\n",
    "\n",
    "\n",
    "# from delta.tables import *\n",
    "# deltaTable = DeltaTable.forPath(spark, \"/path/to/delta/table/\")\n",
    "\n",
    "# deltaTable.restoreToVersion(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                                                           |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|3      |2024-01-19 22:13:54.838|NULL  |NULL    |RESTORE  |{version -> 0, timestamp -> NULL}     |NULL|NULL    |NULL     |2          |Serializable  |false        |{numRestoredFiles -> 0, removedFilesSize -> 0, numRemovedFiles -> 0, restoredFilesSize -> 0, numOfFilesAfterRestore -> 1, tableSizeAfterRestore -> 692}    |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|2      |2024-01-19 22:09:22.127|NULL  |NULL    |RESTORE  |{version -> 0, timestamp -> NULL}     |NULL|NULL    |NULL     |1          |Serializable  |false        |{numRestoredFiles -> 1, removedFilesSize -> 692, numRemovedFiles -> 1, restoredFilesSize -> 692, numOfFilesAfterRestore -> 1, tableSizeAfterRestore -> 692}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|1      |2024-01-19 22:04:25.781|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |0          |Serializable  |false        |{numFiles -> 1, numOutputRows -> 2, numOutputBytes -> 692}                                                                                                 |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|0      |2024-01-19 22:04:11.99 |NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 2, numOutputBytes -> 692}                                                                                                 |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"describe history {dtname};\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|1   |2   |\n",
      "|3   |4   |\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"select * from {dtname} VERSION AS OF 0;\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta table merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_delta = (\n",
    "    spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(\"./output/users_df\")\n",
    ")\n",
    "users_updated_delta = (\n",
    "    spark.read.format(\"delta\")\n",
    "    .option(\"versionAsOf\", 1)\n",
    "    .load(\"./output/users_updated_df\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------+-----+\n",
      "| id|username|         email|phone|\n",
      "+---+--------+--------------+-----+\n",
      "|  1|    john|john@gmail.com|12345|\n",
      "|  2|    jane|jane@gmail.com|45645|\n",
      "|  3|    rick|rick@gmail.com|78678|\n",
      "+---+--------+--------------+-----+\n",
      "\n",
      "+---+--------+----------------+-----+\n",
      "| id|username|           email|phone|\n",
      "+---+--------+----------------+-----+\n",
      "|  1|    john|  john@gmail.com|    0|\n",
      "|  2|    jane|jane02@gmail.com|12345|\n",
      "|  3|    rick|  rick@gmail.com|78678|\n",
      "|  4|    mike|  mike@gmail.com| 9787|\n",
      "+---+--------+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_delta.show()\n",
    "users_updated_delta.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_table = \"delta.`F:\\\\development\\\\learn_spark\\\\output\\\\users_df`\"\n",
    "users_updated_table = \"delta.`F:\\\\development\\\\learn_spark\\\\output\\\\users_updated_df`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    f\"\"\"\n",
    "\n",
    "insert into {users_updated_table} (id, username, email, phone)\n",
    "    VALUES (\n",
    "        5,\n",
    "        'some new name',\n",
    "        'somenewemail@fasdas.com',\n",
    "        55667\n",
    "    );\n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|5                |4               |0               |1                |\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    f\"\"\"\n",
    "\n",
    "  MERGE INTO {users_table} as users\n",
    "  USING {users_updated_table} as usersupd\n",
    "  ON users.id = usersupd.id\n",
    "  WHEN MATCHED THEN\n",
    "    UPDATE SET\n",
    "      id = usersupd.id,\n",
    "      username = usersupd.username,\n",
    "      email = usersupd.email,\n",
    "      phone = usersupd.phone\n",
    "  WHEN NOT MATCHED\n",
    "    THEN INSERT (\n",
    "      id,\n",
    "      username,\n",
    "      email,\n",
    "      phone\n",
    "    )\n",
    "    VALUES (\n",
    "        usersupd.id,\n",
    "        usersupd.username,\n",
    "        usersupd.email,\n",
    "        usersupd.phone\n",
    "    );\n",
    "\n",
    "    \"\"\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----------------------+-----+\n",
      "|id |username     |email                  |phone|\n",
      "+---+-------------+-----------------------+-----+\n",
      "|1  |john         |john@gmail.com         |0    |\n",
      "|2  |jane         |jane02@gmail.com       |12345|\n",
      "|3  |rick         |rick@gmail.com         |78678|\n",
      "|4  |mike         |mike@gmail.com         |9787 |\n",
      "|5  |some new name|somenewemail@fasdas.com|55667|\n",
      "+---+-------------+-----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"select * from {users_table};\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                                                                                                                                                            |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|14     |2024-01-19 22:21:50.527|NULL  |NULL    |MERGE    |{predicate -> [\"(id#16978 = id#16982)\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|NULL|NULL    |NULL     |13         |Serializable  |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1359, numTargetBytesRemoved -> 1277, numTargetRowsMatchedUpdated -> 4, executionTimeMs -> 586, numTargetRowsInserted -> 1, numTargetRowsMatchedDeleted -> 0, scanTimeMs -> 294, numTargetRowsUpdated -> 4, numOutputRows -> 5, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 5, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 288}   |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|13     |2024-01-19 22:19:18.99 |NULL  |NULL    |MERGE    |{predicate -> [\"(id#14437 = id#14441)\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|NULL|NULL    |NULL     |12         |Serializable  |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1277, numTargetBytesRemoved -> 1277, numTargetRowsMatchedUpdated -> 4, executionTimeMs -> 689, numTargetRowsInserted -> 0, numTargetRowsMatchedDeleted -> 0, scanTimeMs -> 417, numTargetRowsUpdated -> 4, numOutputRows -> 4, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 4, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 268}   |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|12     |2024-01-19 22:19:09.596|NULL  |NULL    |MERGE    |{predicate -> [\"(id#11396 = id#11422)\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|NULL|NULL    |NULL     |11         |Serializable  |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1277, numTargetBytesRemoved -> 1277, numTargetRowsMatchedUpdated -> 4, executionTimeMs -> 2285, numTargetRowsInserted -> 0, numTargetRowsMatchedDeleted -> 0, scanTimeMs -> 1824, numTargetRowsUpdated -> 4, numOutputRows -> 4, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 4, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 454} |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|11     |2024-01-16 13:05:29.309|NULL  |NULL    |MERGE    |{predicate -> [\"(id#21931 = id#21939)\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|NULL|NULL    |NULL     |10         |Serializable  |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1277, numTargetBytesRemoved -> 1245, numTargetRowsMatchedUpdated -> 3, executionTimeMs -> 1484, numTargetRowsInserted -> 1, numTargetRowsMatchedDeleted -> 0, scanTimeMs -> 1113, numTargetRowsUpdated -> 3, numOutputRows -> 4, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 4, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 366} |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|10     |2024-01-16 13:05:24.488|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}                                                                                                                                         |NULL|NULL    |NULL     |9          |Serializable  |false        |{numFiles -> 1, numOutputRows -> 3, numOutputBytes -> 1245}                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|9      |2024-01-15 14:00:44.922|NULL  |NULL    |MERGE    |{predicate -> [\"(id#15545 = id#15553)\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|NULL|NULL    |NULL     |8          |Serializable  |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1277, numTargetBytesRemoved -> 1245, numTargetRowsMatchedUpdated -> 3, executionTimeMs -> 900, numTargetRowsInserted -> 1, numTargetRowsMatchedDeleted -> 0, scanTimeMs -> 520, numTargetRowsUpdated -> 3, numOutputRows -> 4, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 4, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 375}   |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|8      |2024-01-15 14:00:41.488|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}                                                                                                                                         |NULL|NULL    |NULL     |7          |Serializable  |false        |{numFiles -> 1, numOutputRows -> 3, numOutputBytes -> 1245}                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|7      |2024-01-06 15:44:41.255|NULL  |NULL    |MERGE    |{predicate -> [\"(id#14684 = id#14692)\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|NULL|NULL    |NULL     |6          |Serializable  |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1277, numTargetBytesRemoved -> 1245, numTargetRowsMatchedUpdated -> 3, executionTimeMs -> 2842, numTargetRowsInserted -> 1, numTargetRowsMatchedDeleted -> 0, scanTimeMs -> 1456, numTargetRowsUpdated -> 3, numOutputRows -> 4, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 4, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 1378}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|6      |2024-01-06 15:44:31.743|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}                                                                                                                                         |NULL|NULL    |NULL     |5          |Serializable  |false        |{numFiles -> 1, numOutputRows -> 3, numOutputBytes -> 1245}                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|5      |2024-01-02 16:06:30.303|NULL  |NULL    |MERGE    |{predicate -> [\"(id#37378 = id#37386)\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|NULL|NULL    |NULL     |4          |Serializable  |false        |{numTargetRowsCopied -> 1, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1355, numTargetBytesRemoved -> 1355, numTargetRowsMatchedUpdated -> 4, executionTimeMs -> 606, numTargetRowsInserted -> 0, numTargetRowsMatchedDeleted -> 0, scanTimeMs -> 350, numTargetRowsUpdated -> 4, numOutputRows -> 5, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 4, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 253}   |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|4      |2024-01-02 16:06:21.966|NULL  |NULL    |MERGE    |{predicate -> [\"(id#37378 = id#37386)\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|NULL|NULL    |NULL     |3          |Serializable  |false        |{numTargetRowsCopied -> 1, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1355, numTargetBytesRemoved -> 1273, numTargetRowsMatchedUpdated -> 3, executionTimeMs -> 729, numTargetRowsInserted -> 1, numTargetRowsMatchedDeleted -> 0, scanTimeMs -> 426, numTargetRowsUpdated -> 3, numOutputRows -> 5, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 4, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 301}   |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|3      |2024-01-02 16:04:45.596|NULL  |NULL    |MERGE    |{predicate -> [\"(id#37378 = id#37386)\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|NULL|NULL    |NULL     |2          |Serializable  |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1273, numTargetBytesRemoved -> 1245, numTargetRowsMatchedUpdated -> 3, executionTimeMs -> 998, numTargetRowsInserted -> 1, numTargetRowsMatchedDeleted -> 0, scanTimeMs -> 569, numTargetRowsUpdated -> 3, numOutputRows -> 4, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 4, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 424}   |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|2      |2024-01-02 16:03:54.029|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}                                                                                                                                         |NULL|NULL    |NULL     |1          |Serializable  |false        |{numFiles -> 1, numOutputRows -> 3, numOutputBytes -> 1245}                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|1      |2024-01-02 16:01:05.143|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}                                                                                                                                         |NULL|NULL    |NULL     |0          |Serializable  |false        |{numFiles -> 1, numOutputRows -> 3, numOutputBytes -> 1245}                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "|0      |2024-01-02 15:20:29.552|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}                                                                                                                                         |NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 3, numOutputBytes -> 1277}                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |NULL        |Apache-Spark/3.5.0 Delta-Lake/3.0.0|\n",
      "+-------+-----------------------+------+--------+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"describe history {users_table};\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
